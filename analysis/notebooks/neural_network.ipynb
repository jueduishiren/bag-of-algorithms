{
 "metadata": {
  "name": "",
  "signature": "sha256:b3d33f42adeac09ddb415c6b6f95ebfee21064bbd824c7b5862a2a9ec5a1311a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Supervised Neural Network "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Building Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from algorithms.datasets import split_dataset, load_higgs_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "raw_data = load_higgs_train()\n",
      "features, weights, labels = raw_data\n",
      "print features.shape, weights.shape, labels.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:algorithms:Loaded higgs training dataset of size 68114\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(68114, 13) (68114,) (68114,)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order for our networks to learn anything, we need a dataset that contains inputs and targets. PyBrain has the pybrain.dataset package for this, and we will use the SupervisedDataSet class for our needs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets import ClassificationDataSet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ClassificationDataset needs to be initialized with two arguments, input size and target size.\n",
      "In this case, input size is the vector lenght of the features, and output size is label which is 1 dimensional vector"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = ClassificationDataSet(features.shape[1], 1, nb_classes=len(set(labels)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = np.array([1 if l=='b' else 0 for l in labels])\n",
      "for i in range(len(features)):\n",
      "    ds.addSample(features.iloc[i], labels[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tstdata, trndata = ds.splitWithProportion(0.33)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Number of training patterns: \", len(trndata)\n",
      "print \"Input and output dimensions: \", trndata.indim, trndata.outdim\n",
      "print \"First sample (input, target, class):\"\n",
      "print trndata['input'][0], trndata['target'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of training patterns:  45637\n",
        "Input and output dimensions:  13 1\n",
        "First sample (input, target, class):\n",
        "[  89.744   13.55    59.149  116.344    2.636  284.584   -0.54     1.362\n",
        "   61.619  278.876    0.588    0.479    0.975] [ 1.]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Training Network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.tools.shortcuts import buildNetwork\n",
      "from pybrain.structure import SoftmaxLayer\n",
      "from pybrain.supervised.trainers import BackpropTrainer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fnn = buildNetwork( trndata.indim, 5, trndata.outdim, outclass=SoftmaxLayer )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer = BackpropTrainer( fnn, dataset=trndata, momentum=0.1, verbose=True, weightdecay=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.utilities import percentError"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "error_data = []\n",
      "for i in range(20):\n",
      "    trainer.trainEpochs( i )\n",
      "    trnerror = percentError( trainer.testOnClassData(),trndata['class'] )\n",
      "    tsterror = percentError( trainer.testOnClassData(dataset=tstdata ), tstdata['class'] )\n",
      "    print \"epoch: %4d\" % trainer.totalepochs, \\\n",
      "          \"  train error: %5.2f%%\" % trnerror, \\\n",
      "          \"  test error: %5.2f%%\" % tsterror\n",
      "    error_data.append([i, trnerror, tsterror])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch:   20   train error:  0.00%   test error:  0.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.235039551241\n",
        "epoch:   21"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   train error:  0.00%   test error:  0.00%\n",
        "Total error:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.235039551241\n",
        "Total error:"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame.from_records(error_data, columns=['iteration', 'training_error', 'test_error'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "error_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[19, 0.0021912045051164625, 0.004448992303243316]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}